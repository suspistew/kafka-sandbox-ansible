broker:
  config:
    port: 9092

kafka:
  connect:
    distributed:
      config_file: /etc/kafka/connect-distributed.properties
      service_name: confluent-kafka-connect
      systemd_override: /etc/systemd/system/confluent-kafka-connect.service.d
      user: cp-kafka-connect
      group: confluent
      environment:
        KAFKA_HEAP_OPTS: "-Xmx256M -Dkafka.logs.dir=/var/log/kafka-connect"
      config:
        rest.port: 8083
        consumer.interceptor.classes: io.confluent.monitoring.clients.interceptor.MonitoringConsumerInterceptor
        producer.interceptor.classes: io.confluent.monitoring.clients.interceptor.MonitoringProducerInterceptor
        ssl.endpoint.identification.algorithm: ""
        consumer.ssl.endpoint.identification.algorithm: ""
        producer.ssl.endpoint.identification.algorithm: ""
        config.storage.replication.factor: 1
        offsets.topic.replication.factor: 1
        config.storage.topic: connect-configs
        group.id: connect-cluster
        internal.key.converter: org.apache.kafka.connect.json.JsonConverter
        internal.key.converter.schemas.enable: false
        internal.value.converter: org.apache.kafka.connect.json.JsonConverter
        internal.value.converter.schemas.enable: false
        offset.flush.interval.ms: 10000
        offset.storage.replication.factor: 1
        offset.storage.topic: connect-offsets
        status.storage.replication.factor: 1
        status.storage.topic: connect-status
        key.converter: io.confluent.connect.avro.AvroConverter
        value.converter: io.confluent.connect.avro.AvroConverter
        plugin.path: /usr/share/java
      systemd:
        enabled: yes
        state: started
